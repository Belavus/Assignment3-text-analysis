{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3 - Text Analysis\n",
    "An explanation this assignment could be found in the .pdf explanation document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Materials to review for this assignment\n",
    "<h4>From Moodle:</h4> \n",
    "<h5><u>Review the notebooks regarding the following python topics</u>:</h5>\n",
    "<div class=\"alert alert-info\">\n",
    "&#x2714; <b>Working with strings</b> (tutorial notebook)<br/>\n",
    "&#x2714; <b>Text Analysis</b> (tutorial notebook)<br/>\n",
    "&#x2714; <b>Hebrew text analysis tools (tokenizer, wordnet)</b> (moodle example)<br/>\n",
    "&#x2714; <b>(brief review) All previous notebooks</b><br/>\n",
    "</div> \n",
    "<h5><u>Review the presentations regarding the following topics</u>:</h5>\n",
    "<div class=\"alert alert-info\">\n",
    "&#x2714; <b>Text Analysis</b> (lecture presentation)<br/>\n",
    "&#x2714; <b>(brief review) All other presentations</b><br/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Personal Details:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Details Student 1:\n",
    "# 324602739\n",
    "# Details Student 2:\n",
    "# -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preceding Step - import modules (packages)\n",
    "This step is necessary in order to use external modules (packages). <br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# --------------------------------------\n",
    "\n",
    "\n",
    "# --------------------------------------\n",
    "# ------------- visualizations:\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "# --------------------------------------\n",
    "\n",
    "\n",
    "# ---------------------------------------\n",
    "import sklearn\n",
    "from sklearn import preprocessing, metrics, pipeline, model_selection, feature_extraction \n",
    "from sklearn import naive_bayes, linear_model, svm, neural_network, neighbors, tree\n",
    "from sklearn import decomposition, cluster\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score, silhouette_score\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, LabelEncoder\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import Perceptron, SGDClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# ---------------------------------------\n",
    "\n",
    "\n",
    "# ----------------- output and visualizations: \n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.simplefilter(\"ignore\")\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(\"ignore\", category=ConvergenceWarning)\n",
    "# show several prints in one cell. This will allow us to condence every trick in one cell.\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "%matplotlib inline\n",
    "pd.pandas.set_option('display.max_columns', None)\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "# ---------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text analysis and String manipulation imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------\n",
    "# --------- Text analysis and Hebrew text analysis imports:\n",
    "# vectorizers:\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# regular expressions:\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (optional) Hebrew text analysis - WordNet (for Hebrew)\n",
    "Note: the WordNet is not a must"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (optional) Only if you didn't install Wordnet (for Hebrew) use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word net installation:\n",
    "# unmark if you want to use and need to install\n",
    "# !pip install wn\n",
    "# !python -m wn download omw-he:1.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word net import:\n",
    "# unmark if you want to use:\n",
    "# import wn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (optional) Hebrew text analysis - hebrew_tokenizer (Tokenizer for Hebrew)\n",
    "Note: the hebrew_tokenizer is not a must"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (optional) Only if you didn't install hebrew_tokenizer use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hebrew tokenizer installation:\n",
    "# unmark if you want to use and need to install:\n",
    "# !pip install hebrew_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hebrew tokenizer import:\n",
    "# unmark if you want to use:\n",
    "# import hebrew_tokenizer as ht"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading input files\n",
    "Reading input files for train annotated corpus (raw text data) corpus and for the test corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filename = 'annotated_corpus_for_train.csv'\n",
    "test_filename  = 'corpus_for_test.csv'\n",
    "df_train = pd.read_csv(train_filename, index_col=None, encoding='utf-8')\n",
    "df_test  = pd.read_csv(test_filename, index_col=None, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>story</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>כשחבר הזמין אותי לחול, לא באמת חשבתי שזה יקרה,...</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>לפני שהתגייסתי לצבא עשיתי כל מני מיונים ליחידו...</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>מאז שהתחילו הלימודים חלומו של כל סטודנט זה הפנ...</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>כשהייתי ילד, מטוסים היה הדבר שהכי ריתק אותי. ב...</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>‏הייתי מדריכה בכפר נוער ומתאם הכפר היינו צריכי...</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               story gender\n",
       "0  כשחבר הזמין אותי לחול, לא באמת חשבתי שזה יקרה,...      m\n",
       "1  לפני שהתגייסתי לצבא עשיתי כל מני מיונים ליחידו...      m\n",
       "2  מאז שהתחילו הלימודים חלומו של כל סטודנט זה הפנ...      f\n",
       "3  כשהייתי ילד, מטוסים היה הדבר שהכי ריתק אותי. ב...      m\n",
       "4  ‏הייתי מדריכה בכפר נוער ומתאם הכפר היינו צריכי...      f"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_example_id</th>\n",
       "      <th>story</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>כל קיץ אני והמשפחה נוסעים לארצות הברית לוס אנג...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>הגעתי לשירות המדינה אחרי שנתיים כפעיל בתנועת \"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>אחת האהבות הגדולות שלי אלו הכלבים שלי ושל אישת...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>רגע הגיוס לצבא היה הרגע הכי משמעותי עבורי, אני...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>אני הגעתי לברזיל ישר מקולומביה וגם אני עשיתי ע...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_example_id                                              story\n",
       "0                0  כל קיץ אני והמשפחה נוסעים לארצות הברית לוס אנג...\n",
       "1                1  הגעתי לשירות המדינה אחרי שנתיים כפעיל בתנועת \"...\n",
       "2                2  אחת האהבות הגדולות שלי אלו הכלבים שלי ושל אישת...\n",
       "3                3  רגע הגיוס לצבא היה הרגע הכי משמעותי עבורי, אני...\n",
       "4                4  אני הגעתי לברזיל ישר מקולומביה וגם אני עשיתי ע..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your implementation:\n",
    "Write your code solution in the following code-cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_copy = df_train.copy()\n",
    "df_test_copy = df_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'כשהייתי ילד, מטוסים היה הדבר שהכי ריתק אותי. בתור בן למפקד טייסת בחיל האוויר, הסיפורים שהקריאו לי לפני השינה לא היו סיפור בחמשת הבלונים, אלא מלחמות ישראל, ובעיקר באוויר. החדר היה מלא בפוסטרים ודגמים של כל מטוס אפשרי שהיה אי פעם למדינת ישראל ושכנותיה. זה לא הפתיע אף אחד, לא זה ולא העובדה שבגיל 13 הייתי הקפטן של מועדון הטיסנים של רחובות. בגיל 16 התחלתי מיוני טיס, להיות טייס היה החלום הכי גדול שלי, וכמובן שלא יכולתי לאכזב את אבא שלי, רציתי שהוא יהיה גאה בי. כל מבחן שהביאו לי עברתי בהצטיינות יתרה, כל שלב סיימתי בין הראשונים. זהרתי. הייתי מגיע הביתה מספר לאבא שלי והמבט הגאה היה שווה הכול. אחרי שעברתי את המיונים בהצלחה התחלתי את קורס הטיס, גם שם הצטיינתי בכל המבחנים ובכל הטסטים, הייתי בין החניכים המוכשרים שהיו אז בבית ספר לטיס. ידעתי שאני הולך להיות טייס קרב, עם נתונים כמו שלי זה היה ברור גם לי וגם ולאבא שלי. אני זוכר שבסופ\"ש לפני סיום הקורס, בארוחת שישי אני ואבא שלי עמדנו במרפסת. היה לו מבט מתוחכם. המבט המתוחכם תמיד היה הכרטיס ביקור של אבא שלי, בתור מפקד טייסת הוא תמיד שמר בתוכו את הסודות הכי כמוסים של מדינת ישראל, אבל הפעם זה היה שונה, זה היה מבט מתוחכם שמלווה בשמחה וגאווה. הוא ידע משהו שאני לא. תיארתי לעצמי שיכול להיות שהוא כבר יודע מי מהחניכים הולך לאיזה טייסת, וכנראה שהתוצאות שלי כן הבטיחו לי מקום בטייסת קרבית. כששאלתי אותו אם הוא שמע במקרה לאן רוצים לשלוח אותי הוא התעצבן עליי ואמר לי שזה לא מקובל להשתמש בקשרים אישיים. אבא שלי תמיד היה איש מערכתי ולוייאלי אז לא נפגעתי ממנו, הבנתי אותו. ביום ראשון היה הטקס חשיפת כנפיים, כל הברנז\\'ה הצהלית הגיעה. הרמטכ\"ל, מפקד חיל האוויר, מפקדי טייסות. עבור החניכים זה היה כמו להסתכל על זאוס וכל החבורה שלו שירדו מהאולימפוס. אפילו גדי איזנקוט שהוא לא אדם גבוה, בלשון המעטה, היה נראה לנו מינימום כמו 10 מטוסי F-16 שמחוברים אחד לשני לגובה. המעמד וההתרגשות היו בשיאם. בין כל האנשים האלה עמד אבא שלי עם אותו מבט מתוחכם, שמח וגאה, לא הורדתי ממנו את המבט, הוא עדיין ידע משהו שאני לא. ברגע שהתחיל הטקס, הרמטכ\"ל התחיל לעבור חניך וחניך והוריד לו את האיזולירבנד הלבן מהכנפי טיס. כשהוא הגיע אליי, הוא עצר והלך אחורה. לא הבנתי מה קורה. \"למה הוא עצר? יכול להיות שלא סיימתי את הקורס? אבל איך זה יכול להיות, אני המצטיין! איך אני אסתכל לאבא שלי בעיניים ועוד מול הרמטכ\"ל? איזה פאדיחות!\" עבר לי בראש. איך שהאור חזר לי לעיניים ראיתי את אבא שלי ניגש מולי ומוריד לי את האיזולירבנד הלבן מהכנפי טייס. ארבע מילים יצאו לו מהפה \"ברוך הבא לטייסת בן\". ארבע מילים שאני לעולם לא אשכח.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_copy['story'].iloc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning (clearing text of special characters and punctuation marks.)\n",
    "def clean_text(text):\n",
    "    pattern = r\"[^\\w\\s]\"\n",
    "    text = re.sub(pattern,\"\",text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean df_train\n",
    "df_train_copy['story'] = df_train_copy['story'].apply(clean_text)\n",
    "df_train_copy['gender'] = df_train_copy['gender'].map({'m': 1, 'f': 0})\n",
    "\n",
    "#clean df_test\n",
    "df_train_copy['story'] = df_train_copy['story'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'כשהייתי ילד מטוסים היה הדבר שהכי ריתק אותי בתור בן למפקד טייסת בחיל האוויר הסיפורים שהקריאו לי לפני השינה לא היו סיפור בחמשת הבלונים אלא מלחמות ישראל ובעיקר באוויר החדר היה מלא בפוסטרים ודגמים של כל מטוס אפשרי שהיה אי פעם למדינת ישראל ושכנותיה זה לא הפתיע אף אחד לא זה ולא העובדה שבגיל 13 הייתי הקפטן של מועדון הטיסנים של רחובות בגיל 16 התחלתי מיוני טיס להיות טייס היה החלום הכי גדול שלי וכמובן שלא יכולתי לאכזב את אבא שלי רציתי שהוא יהיה גאה בי כל מבחן שהביאו לי עברתי בהצטיינות יתרה כל שלב סיימתי בין הראשונים זהרתי הייתי מגיע הביתה מספר לאבא שלי והמבט הגאה היה שווה הכול אחרי שעברתי את המיונים בהצלחה התחלתי את קורס הטיס גם שם הצטיינתי בכל המבחנים ובכל הטסטים הייתי בין החניכים המוכשרים שהיו אז בבית ספר לטיס ידעתי שאני הולך להיות טייס קרב עם נתונים כמו שלי זה היה ברור גם לי וגם ולאבא שלי אני זוכר שבסופש לפני סיום הקורס בארוחת שישי אני ואבא שלי עמדנו במרפסת היה לו מבט מתוחכם המבט המתוחכם תמיד היה הכרטיס ביקור של אבא שלי בתור מפקד טייסת הוא תמיד שמר בתוכו את הסודות הכי כמוסים של מדינת ישראל אבל הפעם זה היה שונה זה היה מבט מתוחכם שמלווה בשמחה וגאווה הוא ידע משהו שאני לא תיארתי לעצמי שיכול להיות שהוא כבר יודע מי מהחניכים הולך לאיזה טייסת וכנראה שהתוצאות שלי כן הבטיחו לי מקום בטייסת קרבית כששאלתי אותו אם הוא שמע במקרה לאן רוצים לשלוח אותי הוא התעצבן עליי ואמר לי שזה לא מקובל להשתמש בקשרים אישיים אבא שלי תמיד היה איש מערכתי ולוייאלי אז לא נפגעתי ממנו הבנתי אותו ביום ראשון היה הטקס חשיפת כנפיים כל הברנזה הצהלית הגיעה הרמטכל מפקד חיל האוויר מפקדי טייסות עבור החניכים זה היה כמו להסתכל על זאוס וכל החבורה שלו שירדו מהאולימפוס אפילו גדי איזנקוט שהוא לא אדם גבוה בלשון המעטה היה נראה לנו מינימום כמו 10 מטוסי F16 שמחוברים אחד לשני לגובה המעמד וההתרגשות היו בשיאם בין כל האנשים האלה עמד אבא שלי עם אותו מבט מתוחכם שמח וגאה לא הורדתי ממנו את המבט הוא עדיין ידע משהו שאני לא ברגע שהתחיל הטקס הרמטכל התחיל לעבור חניך וחניך והוריד לו את האיזולירבנד הלבן מהכנפי טיס כשהוא הגיע אליי הוא עצר והלך אחורה לא הבנתי מה קורה למה הוא עצר יכול להיות שלא סיימתי את הקורס אבל איך זה יכול להיות אני המצטיין איך אני אסתכל לאבא שלי בעיניים ועוד מול הרמטכל איזה פאדיחות עבר לי בראש איך שהאור חזר לי לעיניים ראיתי את אבא שלי ניגש מולי ומוריד לי את האיזולירבנד הלבן מהכנפי טייס ארבע מילים יצאו לו מהפה ברוך הבא לטייסת בן ארבע מילים שאני לעולם לא אשכח'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_copy['story'].iloc[3]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Split words that end in \"ת\" into two parts by adding a space between them.(not used after)\n",
    "def split_suffix_t(text):\n",
    "    words = text.split()\n",
    "    \n",
    "    for i in range(len(words)):\n",
    "        word = words[i]\n",
    "        if re.search(r'ת$', word):  # Check to see if the word ends with \"ת\"\n",
    "            # Divide the word into two parts: the word and “ת”, adding a space between them\n",
    "            words[i] = re.sub(r'(ת)$', r' \\1', word)\n",
    "    result_text = ' '.join(words)\n",
    "    return result_text\n",
    "\n",
    "df_train_copy['story'] = df_train_copy['story'].apply(split_suffix_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Visualisation`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=======correlations==========\n",
    "\n",
    "# Vectorize the stories\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000)\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df_train_copy['story'])\n",
    "\n",
    "# Create a new DataFrame with vectorized features and gender labels\n",
    "df_vectorized = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_vectorizer.get_feature_names())\n",
    "df_vectorized['gender'] = df_train_copy['gender']\n",
    "\n",
    "# Calculate correlation between vectorized features and gender labels\n",
    "correlation_matrix = df_vectorized.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words with correlation below threshold:\n",
      "['10', 'אבא', 'אביב', 'אבל', 'אדם', 'או', 'אוהב', 'אוכל', 'אולי', 'אותה', 'אותו', 'אותי', 'אותם', 'אותנו', 'אז', 'אחד', 'אחר', 'אחרי', 'אחרת', 'אחת', 'איזה', 'איך', 'אין', 'איפה', 'איתה', 'איתו', 'איתי', 'איתם', 'איתנו', 'אך', 'אכלנו', 'אל', 'אלא', 'אלי', 'אליה', 'אליו', 'אליי', 'אלינו', 'אם', 'אמא', 'אמר', 'אמרה', 'אמרו', 'אמרתי', 'אנחנו', 'אני', 'אנשים', 'אף', 'אפילו', 'אפשר', 'אצל', 'ארוחת', 'ארוך', 'ארוכה', 'אשר', 'את', 'אתה', 'באופן', 'באותה', 'באותו', 'באזור', 'באחד', 'באמצע', 'באמת', 'בארץ', 'בבוקר', 'בבית', 'בגלל', 'בדיוק', 'בדרך', 'בה', 'בהם', 'בהתחלה', 'בו', 'בוקר', 'בזמן', 'בחדר', 'בחיים', 'בי', 'ביום', 'ביחד', 'בין', 'בית', 'בכל', 'בכלל', 'בלי', 'בלילה', 'במהלך', 'במיוחד', 'במלון', 'במקום', 'במשך', 'בנוסף', 'בסדר', 'בסוף', 'בסופו', 'בעבודה', 'בעולם', 'בעיקר', 'בעיר', 'בעקבות', 'בערב', 'בערך', 'בצורה', 'בשבוע', 'בשביל', 'בשנה', 'בשעה', 'בת', 'בתוך', 'בתור', 'בתקופה', 'גדול', 'גדולה', 'גם', 'דבר', 'דברים', 'די', 'דירה', 'דקות', 'דרך', 'האוכל', 'האחרון', 'האחרונה', 'האם', 'האנשים', 'הבית', 'הביתה', 'הבנו', 'הבנתי', 'הגיע', 'הגיעו', 'הגענו', 'הגעתי', 'הדבר', 'הדברים', 'הדירה', 'הדרך', 'ההורים', 'הוא', 'הולך', 'הזאת', 'הזה', 'הזו', 'הזוג', 'הזמן', 'החברה', 'החברים', 'החוויה', 'החולים', 'החיים', 'החלטנו', 'החלטתי', 'החתונה', 'הטיול', 'הטיסה', 'היא', 'היה', 'היו', 'היום', 'הייתה', 'הייתי', 'הים', 'היתה', 'הכי', 'הכל', 'הכלב', 'הלילה', 'הלימודים', 'הלכנו', 'הלכתי', 'הם', 'המון', 'המלון', 'המצב', 'המקום', 'המשחק', 'המשכנו', 'המשפחה', 'הנסיעה', 'הסגר', 'הסיפור', 'העבודה', 'העיר', 'הערב', 'הפעם', 'הצלחנו', 'הצלחתי', 'הקורונה', 'הראשון', 'הראשונה', 'הרבה', 'הרגע', 'הרגשתי', 'הרכב', 'השנה', 'השני', 'השעה', 'התחיל', 'התחילה', 'התחילו', 'התחלנו', 'התחלתי', 'התקופה', 'ואז', 'ואני', 'ואפילו', 'ואת', 'וגם', 'והוא', 'והיא', 'והיה', 'והתחלנו', 'והתחלתי', 'וזה', 'וחצי', 'וכך', 'וכל', 'וכמובן', 'ולא', 'ולאחר', 'ולכן', 'ומה', 'ועוד', 'ועל', 'זאת', 'זה', 'זו', 'זוג', 'זמן', 'חבר', 'חברים', 'חדש', 'חודש', 'חודשים', 'חוויה', 'חולים', 'חזרה', 'חזרנו', 'חיים', 'חלק', 'חצי', 'חשבתי', 'חשוב', 'טוב', 'טובה', 'טובים', 'טיול', 'טיסה', 'ידענו', 'ידעתי', 'יהיה', 'יום', 'יותר', 'יחד', 'יחסית', 'יכול', 'ים', 'ימים', 'יפה', 'יצאנו', 'יצאתי', 'יש', 'ישר', 'ישראל', 'כאילו', 'כאשר', 'כבר', 'כדי', 'כולם', 'כולנו', 'כזה', 'כי', 'כיף', 'כך', 'ככה', 'כל', 'כלום', 'כלל', 'כמה', 'כמו', 'כמובן', 'כמעט', 'כן', 'כסף', 'לא', 'לאט', 'לאכול', 'לארץ', 'לב', 'לבד', 'לבית', 'לבסוף', 'לגור', 'לדבר', 'לדירה', 'לה', 'להבין', 'להגיד', 'להגיע', 'להיות', 'להיכנס', 'להם', 'להמשיך', 'להתחיל', 'לו', 'לחדר', 'לחזור', 'לחפש', 'לטוס', 'לטיול', 'לטייל', 'לי', 'ליד', 'לישון', 'לך', 'לכך', 'לכל', 'לכן', 'ללא', 'ללכת', 'ללמוד', 'למה', 'למחרת', 'למלון', 'למצוא', 'למקום', 'למרות', 'לנו', 'לנסוע', 'לנסות', 'לעבוד', 'לעבודה', 'לעבור', 'לעזור', 'לעלות', 'לעצמי', 'לעשות', 'לפחות', 'לפני', 'לצאת', 'לקבל', 'לקח', 'לקחת', 'לקחתי', 'לקנות', 'לקראת', 'לראות', 'לשחק', 'לשם', 'לתת', 'מאוד', 'מאז', 'מאיתנו', 'מגיע', 'מדהים', 'מדי', 'מה', 'מהבית', 'מהם', 'מהר', 'מול', 'מי', 'מיד', 'מידי', 'מים', 'מיני', 'מישהו', 'מכיוון', 'מכל', 'מכן', 'מלא', 'ממנו', 'ממני', 'ממש', 'מנת', 'מספר', 'מעבר', 'מעט', 'מצאנו', 'מצאתי', 'מקום', 'מקומות', 'מרגיש', 'משהו', 'משם', 'נוסף', 'נורא', 'נחמד', 'ניתן', 'נכנסתי', 'נמצא', 'נסיעה', 'נסענו', 'נסעתי', 'נראה', 'סוף', 'עבודה', 'עבר', 'עברתי', 'עד', 'עדיין', 'עובד', 'עוד', 'עושה', 'עושים', 'עכשיו', 'על', 'עלי', 'עליו', 'עליי', 'עלינו', 'עם', 'עצמו', 'עצמי', 'ערב', 'עשינו', 'עשיתי', 'פה', 'פחות', 'פעם', 'פעמים', 'פשוט', 'פתאום', 'צריכים', 'קורה', 'קורונה', 'קטן', 'קטנה', 'קיבלנו', 'קיבלתי', 'קפה', 'קצת', 'קרה', 'קרוב', 'קשה', 'ראינו', 'ראיתי', 'ראשון', 'רב', 'רבות', 'רבים', 'רגע', 'רואה', 'רוצה', 'רכב', 'רציתי', 'רק', 'שאין', 'שאנחנו', 'שאני', 'שאתה', 'שבו', 'שבוע', 'שבועיים', 'שגם', 'שהוא', 'שהיא', 'שהיה', 'שהיו', 'שהיינו', 'שהייתה', 'שהייתי', 'שוב', 'שום', 'שזה', 'שיש', 'שכל', 'של', 'שלא', 'שלה', 'שלהם', 'שלו', 'שלנו', 'שם', 'שנה', 'שני', 'שנים', 'שעה', 'שצריך', 'תוך', 'תמיד', 'תקופה', 'תקופת']\n"
     ]
    }
   ],
   "source": [
    "# Define the correlation threshold\n",
    "correlation_threshold = 0.1\n",
    "\n",
    "# Filter words based on correlation threshold\n",
    "correlation_with_gender = correlation_matrix['gender']\n",
    "words_below_threshold = correlation_with_gender[abs(correlation_with_gender) < correlation_threshold].index.tolist()\n",
    "\n",
    "print(\"Words with correlation below threshold:\")\n",
    "print(words_below_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation f1_macro function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === cross validation function ===\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "def cross_validation(text_clf,df_train_data,df_train_target):\n",
    "    cross_val_scores = cross_val_score(text_clf, df_train_data, df_train_target, scoring=make_scorer(f1_score,average='macro'), cv=10)\n",
    "    average_f1 = np.mean(cross_val_scores)\n",
    "    print(f\"Average F1 score: {average_f1}\")\n",
    "    return cross_val_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find NB best hyperparameters:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `NB_Classifier & TfidfVectorizer` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('vect', TfidfVectorizer()),\n",
       "                                       ('norm', Normalizer(norm='l1')),\n",
       "                                       ('clf_nb', MultinomialNB())]),\n",
       "             param_grid={'clf_nb__alpha': [0.1, 0.5, 1.0],\n",
       "                         'vect__max_features': [100, 500, 1000]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for MultinomialNB: {'clf_nb__alpha': 0.1, 'vect__max_features': 100}\n",
      "Best F1 score for MultinomialNB: 0.4329778822905296\n"
     ]
    }
   ],
   "source": [
    "text_clf_nb = Pipeline([\n",
    "    ('vect', TfidfVectorizer()),\n",
    "    ('norm', preprocessing.Normalizer(norm='l1')),\n",
    "    ('clf_nb', MultinomialNB()),\n",
    "])\n",
    "\n",
    "#parameters to try\n",
    "param_grid_nb = {\n",
    "    'vect__max_features': [100,500,1000],\n",
    "    'clf_nb__alpha': [0.1, 0.5, 1.0],\n",
    "}\n",
    "\n",
    "# GridSearchCV object\n",
    "grid_search_nb = GridSearchCV(text_clf_nb, param_grid_nb, cv=10, scoring=make_scorer(f1_score,average='macro'))\n",
    "\n",
    "grid_search_nb.fit(df_train_copy['story'], df_train_copy['gender'])\n",
    "\n",
    "print(\"Best parameters for MultinomialNB:\", grid_search_nb.best_params_)\n",
    "print(\"Best F1 score for MultinomialNB:\", grid_search_nb.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_max_features = grid_search_nb.best_params_['vect__max_features']\n",
    "best_alpha = grid_search_nb.best_params_['clf_nb__alpha']\n",
    "\n",
    "best_text_clf_nb = Pipeline([\n",
    "    ('vect', TfidfVectorizer(max_features=best_max_features)),\n",
    "    ('norm', preprocessing.Normalizer(norm='l1')),\n",
    "    ('clf_nb', MultinomialNB(alpha=best_alpha)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1 score: 0.4329778822905296\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.43283582, 0.43283582, 0.43283582, 0.43609023, 0.43609023,\n",
       "       0.43181818, 0.43181818, 0.43181818, 0.43181818, 0.43181818])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validation(best_text_clf_nb, df_train_copy['story'], df_train_copy['gender'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `NB_Classifier & CountVectorizer` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('vect',\n",
       "                                        CountVectorizer(max_features=1000)),\n",
       "                                       ('norm', Normalizer(norm='l1')),\n",
       "                                       ('clf_nb', MultinomialNB())]),\n",
       "             param_grid={'clf_nb__alpha': [0.1, 0.5, 1.0],\n",
       "                         'vect__max_features': [50, 100, 500, 1000]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for MultinomialNB: {'clf_nb__alpha': 0.1, 'vect__max_features': 50}\n",
      "Best F1 score for MultinomialNB: 0.4329778822905296\n"
     ]
    }
   ],
   "source": [
    "text_clf_nb = Pipeline([\n",
    "    ('vect', CountVectorizer(max_features=1000)),\n",
    "    ('norm', preprocessing.Normalizer(norm='l1')),\n",
    "    ('clf_nb', MultinomialNB()),\n",
    "])\n",
    "\n",
    "#parameters to try\n",
    "param_grid_nb = {\n",
    "    'vect__max_features': [50,100,500,1000],\n",
    "    'clf_nb__alpha': [0.1, 0.5, 1.0],\n",
    "}\n",
    "\n",
    "# GridSearchCV object\n",
    "grid_search_nb = GridSearchCV(text_clf_nb, param_grid_nb, cv=10, scoring=make_scorer(f1_score,average='macro'))\n",
    "\n",
    "grid_search_nb.fit(df_train_copy['story'], df_train_copy['gender'])\n",
    "\n",
    "print(\"Best parameters for MultinomialNB:\", grid_search_nb.best_params_)\n",
    "print(\"Best F1 score for MultinomialNB:\", grid_search_nb.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find DecisionTree hyperparameters:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `DecisionTree_Classifier & CountVectorizer` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('vect',\n",
       "                                        CountVectorizer(max_features=1000)),\n",
       "                                       ('norm', Normalizer(norm='l1')),\n",
       "                                       ('clf_tree', DecisionTreeClassifier())]),\n",
       "             param_grid={'clf_tree__max_depth': [None, 10, 20],\n",
       "                         'clf_tree__min_samples_split': [2, 5, 10],\n",
       "                         'vect__max_features': [500, 1000, 1500]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for DecisionTreeClassifier: {'clf_tree__max_depth': None, 'clf_tree__min_samples_split': 10, 'vect__max_features': 1000}\n",
      "Best F1 score for DecisionTreeClassifier: 0.6269245551076756\n"
     ]
    }
   ],
   "source": [
    "text_clf_tree = Pipeline([\n",
    "    ('vect', CountVectorizer(max_features=1000)),\n",
    "    ('norm', preprocessing.Normalizer(norm='l1')),\n",
    "    ('clf_tree', DecisionTreeClassifier()),\n",
    "])\n",
    "\n",
    "param_grid_tree = {\n",
    "    'vect__max_features': [500, 1000, 1500],\n",
    "    'clf_tree__max_depth': [None, 10, 20],\n",
    "    'clf_tree__min_samples_split': [2, 5, 10],\n",
    "}\n",
    "\n",
    "# GridSearchCV\n",
    "grid_search_tree = GridSearchCV(text_clf_tree, param_grid_tree, cv=10, scoring=make_scorer(f1_score,average='macro'))\n",
    "grid_search_tree.fit(df_train_copy['story'], df_train_copy['gender'])\n",
    "\n",
    "print(\"Best parameters for DecisionTreeClassifier:\", grid_search_tree.best_params_)\n",
    "print(\"Best F1 score for DecisionTreeClassifier:\", grid_search_tree.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `DecisionTree_Classifier & TfidfVectorizer` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('vect',\n",
       "                                        TfidfVectorizer(max_features=1000)),\n",
       "                                       ('norm', Normalizer(norm='l1')),\n",
       "                                       ('clf_tree', DecisionTreeClassifier())]),\n",
       "             param_grid={'clf_tree__max_depth': [None, 10, 20],\n",
       "                         'clf_tree__min_samples_split': [2, 5, 10],\n",
       "                         'vect__max_features': [500, 1000, 1500]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for DecisionTreeClassifier: {'clf_tree__max_depth': 20, 'clf_tree__min_samples_split': 2, 'vect__max_features': 1000}\n",
      "Best F1 score for DecisionTreeClassifier: 0.6208470770880161\n"
     ]
    }
   ],
   "source": [
    "text_clf_tree = Pipeline([\n",
    "    ('vect', TfidfVectorizer(max_features=1000)),\n",
    "    ('norm', preprocessing.Normalizer(norm='l1')),\n",
    "    ('clf_tree', DecisionTreeClassifier()),\n",
    "])\n",
    "\n",
    "param_grid_tree = {\n",
    "    'vect__max_features': [500, 1000, 1500],\n",
    "    'clf_tree__max_depth': [None, 10, 20],\n",
    "    'clf_tree__min_samples_split': [2, 5, 10],\n",
    "}\n",
    "\n",
    "# GridSearchCV\n",
    "grid_search_tree = GridSearchCV(text_clf_tree, param_grid_tree, cv=10, scoring=make_scorer(f1_score,average='macro'))\n",
    "\n",
    "grid_search_tree.fit(df_train_copy['story'], df_train_copy['gender'])\n",
    "\n",
    "print(\"Best parameters for DecisionTreeClassifier:\", grid_search_tree.best_params_)\n",
    "print(\"Best F1 score for DecisionTreeClassifier:\", grid_search_tree.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `MLP_Classifier & TfidfVectorizer` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('vect',\n",
       "                                        TfidfVectorizer(max_features=1000,\n",
       "                                                        ngram_range=(1, 3))),\n",
       "                                       ('norm', Normalizer(norm='l1')),\n",
       "                                       ('clf_mlp', MLPClassifier())]),\n",
       "             param_grid={'clf_mlp__alpha': [0.0001, 0.001, 0.01],\n",
       "                         'clf_mlp__hidden_layer_sizes': [(100,), (100, 50),\n",
       "                                                         (200, 100)],\n",
       "                         'vect__max_features': [1500, 2000, 2500]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for MLPClassifier: {'clf_mlp__alpha': 0.01, 'clf_mlp__hidden_layer_sizes': (200, 100), 'vect__max_features': 2000}\n",
      "Best F1 score for MLPClassifier: 0.6744466428822244\n"
     ]
    }
   ],
   "source": [
    "text_clf_mlp = Pipeline([\n",
    "    ('vect', TfidfVectorizer(ngram_range=(1, 3)),\n",
    "    ('norm', preprocessing.Normalizer(norm='l1')),\n",
    "    ('clf_mlp', MLPClassifier()),\n",
    "])\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid_mlp = {\n",
    "    'vect__max_features': [1500,2000,2500],\n",
    "    'clf_mlp__hidden_layer_sizes': [(100,), (100, 50), (200, 100)],\n",
    "    'clf_mlp__alpha': [0.0001, 0.001, 0.01],\n",
    "}\n",
    "\n",
    "# Create a scorer\n",
    "scorer = make_scorer(f1_score, average='macro')\n",
    "\n",
    "# Perform GridSearchCV\n",
    "grid_search_mlp = GridSearchCV(text_clf_mlp, param_grid_mlp, cv=10, scoring=scorer)\n",
    "\n",
    "grid_search_mlp.fit(df_train_copy['story'], df_train_copy['gender'])\n",
    "\n",
    "print(\"Best parameters for MLPClassifier:\", grid_search_mlp.best_params_)\n",
    "print(\"Best F1 score for MLPClassifier:\", grid_search_mlp.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_mlp = grid_search_mlp.best_params_\n",
    "best_text_clf_mlp = Pipeline([\n",
    "    ('tfidf_vect', TfidfVectorizer(ngram_range=(1, 4),max_features=best_params_mlp['vect__max_features'])),\n",
    "    ('norm', preprocessing.Normalizer(norm='l1')),\n",
    "    ('clf_mlp', MLPClassifier(\n",
    "        hidden_layer_sizes=best_params_mlp['clf_mlp__hidden_layer_sizes'],\n",
    "        alpha=best_params_mlp['clf_mlp__alpha']\n",
    "    )),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ===================Model Testing==================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf_vect',\n",
       "                 TfidfVectorizer(max_features=2000, ngram_range=(1, 4))),\n",
       "                ('norm', Normalizer(norm='l1')),\n",
       "                ('clf_mlp',\n",
       "                 MLPClassifier(alpha=0.01, hidden_layer_sizes=(200, 100)))])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train TF-IDF vectorizer and MLPClassifier on training data\n",
    "best_text_clf_mlp.fit(df_train_copy['story'], df_train_copy['gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take first five and last five rows of df_test:\n",
    "first_5_rows = df_test_copy.head(5)\n",
    "last_5_rows = df_test_copy.tail(5)\n",
    "\n",
    "selected_rows = pd.concat([first_5_rows, last_5_rows])\n",
    "\n",
    "predicted = best_text_clf_mlp.predict(selected_rows['story'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predicted = selected_rows.drop(columns=['story'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predicted['predicted_category'] = predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predicted['predicted_category'] = df_predicted['predicted_category'].map({1:'m',0:'f'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_example_id</th>\n",
       "      <th>predicted_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>318</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>319</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>320</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>321</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>322</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     test_example_id predicted_category\n",
       "0                  0                  m\n",
       "1                  1                  m\n",
       "2                  2                  m\n",
       "3                  3                  m\n",
       "4                  4                  f\n",
       "318              318                  m\n",
       "319              319                  m\n",
       "320              320                  m\n",
       "321              321                  m\n",
       "322              322                  m"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'אני הגעתי לברזיל ישר מקולומביה וגם אני עשיתי עבודת מחקר על ברזיל והחלטתי בסוף לטוס נחתתי בריו דה ז׳נרו ויצרתי קשר עם איתמר המרכז הישראלי ברזיל והוא הסביר לי שהכל פה רגיל, הכל מתוייר ואין מה לדאוג הקורונה פה היא לא קשה וברזיל נפתחה ממזמן לתיירים. הגעתי ביום חמישי לברזיל וכבר הספקתי להסתובב בעיר, הקניונים מלאים בתיירים ומקומיים, המסעדות מאוד זולות והחוף ים מפוצץ ברזיל מדינה טרופית ולפעמים יורד גשם, אז אם יורד גשם, יש לא מעט דברים לעשות בריו שאפשר להתייעץ עם איתמר. אבל בגדול, עכשיו ברזיל נכנסת לעונת הקיץ. אז נחזור שוב פעם לאיתמר התותח שלא החסיר מאיתנו אף פיסת מידע על העיר והסביר לנו על כל אטרקציה אפשרית. ביום שישי יצאתי דרכו לסיור בעיר מושלם בריו הוא אסף את כולנו ברכב הפרטי שלו כל אחד מההוסטל שלו (יש לציין שבעונה של הגל בברזיל לאיתמר יש סוכנות של טיולים וסיורים, עובדים, מיניבוסים והוא דואג להכל) *התחלנו את הסיור בפסל הגדול של ישו Cristo Redentor שנחשב לפלא עולם ממנו אפשר לראות את כל החופים המושלמים של ריו ונוף מטורף על כל העיר *המשכנו למדרגות הכי מתוירות ופוטוגניות של העיר Escadaria Selarón שם איתמר הסביר לנו על המדרגות והמשמעות האמיתית שלהן( בלי ספויילרים), אפשר לראות אריחי קרמיקה מכל מדינה בעולם ויש גם אריחים עם כיתוב בעברית. *אחרי זה הלכנו למסעדה לבנונית מאוד טעימה וזולה יש שם אופציות טבעוניות וצמחוניות( לי אישית היה חשוב כי אני אוכלת כשר בחול ואיתמר דאג להכל) *בהמשך הלכנו לקיר גרפיטי הכי גדול בעולם שם אפשר לעשות תמונות מגניבות * והחלק הכי חשוב בסיור הוא הפבלות של ברזיל, ירדנו מהרכב ישר למגרש כדורגל של הפאבלה שיחקנו עם המקומיים שכל כך התרגשו מהמשחק ובסוף גם קנינו להם שתייה וחטיפים הצטרף אלינו מדריך מקומי ראש מאפיה לשעבר שעשה לנו סיור בפאבלות והסביר לנו את כל ההיסטוריה של המקום וכמובן סיפר לנו את סיפור חייו המרתק. בהליכה בתוך הפאבלה תראו בצדדים המון מקומיים עם נשקים אין מה לחשוש כי כולם מכירים את המדריך ויודעים שאנחנו בסדר. הגענו בסוף למרכז של הסמבה, הסבירו לנו שבכל פאבלה יש מרכז כזה שעוזר לילדים של הפאבלות להתעסק בדברים אחרים ולא להשאב לפשע ולעוני של המקום סוג של דרך מילוט מכל הבעיות של המקום. ארגנו לנו מופע מיוחד של תופים, של רקדנית סמבה לימדה אותנו צעדים של הסמבה ובהמשך עשו לנו מופע של קפוארה וגם שם לקחנו חלק בכל הצעדים. כולם קיבלו אותנו כל כך יפה וזה סיור שאסור לוותר עליו!! *אני אישית עשיתי עד עכשיו את האטרקציה הזאת אבל חברה שלי עשתה דרך איתמר את הדאון שאסור לפספס אותו ויש עוד מליון אטרקציות בעיר שווה לדבר איתו !! *ברזיל היא בירת הכדורגל העולמי ואנחנו נפלנו על סופש של משחק דרבי מטורף ואיתמר דאג לנו לכרטיסים טובים ומוזלים לאצטדיון כדורגל Maracanã - מי שלא יודע על כל דבר בברזיל מבקשים cpf זה מסמך מיוחד כמו תעודת זהות שמראה שאתה תושב המקום ולא תושב חוץ ומקנה כניסה למקומות והנחות ואיתמר סידר לנו כניסה בלי בירוקרטיות מיותרות. אני ישנה בהוסטל social הוא 3 דקות הליכה מהרצועת חוף הכי יפה שיש Copacabana וליד ההוסטל במרחק הליכה של כמה דקות יש סופרים אפשר לבשל בהוסטל *מבחינת מסעדות יש ממול להוסטל את האסאי הכי שווה שיש ויש עוד מסעדות של המבורגרים ובשרים אני אישית מבחינת כשרות לא טעמתי אבל כולם המליצו ממש. בריו יש חיי לילה מטורפים מסיבות מטורפות מועדונים וברים טובים יש את הרחוב המרכזי של כל המסיבות קוראים לו Lapa אנחנו אישית נעזרנו בצעירים שיושבים בקבלה בהוסטל שלנו הם מוכרים לנו כרטיסים מוזלים למסיבות דרך איתמר עם הטבות של שתייה בחינם כל הערב וממליצים לנו על המסיבות הכי טובות שיש.'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['story'].iloc[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save output to csv (optional)\n",
    "After you're done save your output to the 'classification_results.csv' csv file.<br/>\n",
    "We assume that the dataframe with your results contain the following columns:\n",
    "* column 1 (left column): 'test_example_id'  - the same id associated to each of the test stories to be predicted.\n",
    "* column 2 (right column): 'predicted_category' - the predicted gender value for each of the associated story. \n",
    "\n",
    "Assuming your predicted values are in the `df_predicted` dataframe, you should save you're results as following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predicted.to_csv('classification_results.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
